import torch
from torch.utils.data import Dataset
import pandas as pd

from data_parsing.helpers import DatasetFileLoader

def build_vocab(text):
    unique_chars = sorted(set(text))
    unique_chars.remove('\n')
    char_to_index = {char: idx for idx, char in enumerate(unique_chars)}
    index_to_char = {idx: char for char, idx in char_to_index.items()}
    return char_to_index, index_to_char

class CharDataset(Dataset):
    def __init__(self, data: str,context_len=32):
        self.context_len = context_len
        self.data_indices =data 

        print(self.data_indices)
    def __len__(self):
        return len(self.data_indices) - self.context_len

    def __getitem__(self, idx):
        input_seq = self.data_indices[idx:idx+self.context_len]
        target_char = self.data_indices[self.data_indices[idx+self.context_len]]
        return input_seq, target_char
    
class CharDatasetWrapper():
    # Load training data
    def __init__(self, device, data_directory, context_length: int = 32, dataset_fraction: float = 1):
        data_loader = DatasetFileLoader()
        data_loader.load(data_directory, dataset_fraction)

        # TODO: Fix this so getting [0] and slicing first line isn't needed
        train_data = data_loader.train_data[0][1:]

        dev_data = data_loader.dev_data[0][1:]

        train_text = "\n".join(train_data)
        dev_text = "\n".join(dev_data)

        # Build vocabulary 
        self._vocab, _ = build_vocab(train_text)

        train_data = torch.tensor([self._vocab[char] for char in train_text if char in self._vocab])
        dev_data = torch.tensor([self._vocab[char] for char in dev_text if char in self._vocab])

        self._train_dataset = CharDataset(train_data,  context_length)
        self._dev_dataset = CharDataset(dev_data, context_length)

    def vocab(self):
        return self._vocab
    
    def train_dataset(self):
        return self._train_dataset
    
    def dev_dataset(self):
        return self._dev_dataset
    
    def vocab_size(self):
        return len(self._vocab)
